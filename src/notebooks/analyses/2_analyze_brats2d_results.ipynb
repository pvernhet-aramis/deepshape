{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# 2d Brain model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting root path to : /network/lustre/dtlake01/aramis/users/paul.vernhet/Scripts/Ongoing/MICCAI2020/deepshape\n",
      "Setting root path to : /network/lustre/dtlake01/aramis/users/paul.vernhet/Scripts/Ongoing/MICCAI2020/deepshape\n"
     ]
    }
   ],
   "source": [
    "### Base ###\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from argparse import Namespace\n",
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import fnmatch\n",
    "import itertools\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import PIL.Image as pimg\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "### Visualization ###\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "rc('font', **{'family':'serif','serif':['Palatino']})\n",
    "%matplotlib inline\n",
    "\n",
    "parent = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))\n",
    "sys.path.insert(0, parent)\n",
    "os.chdir(parent)\n",
    "print('Setting root path to : {}'.format(parent))\n",
    "\n",
    "from src.support.base_miccai import *\n",
    "from src.in_out.datasets_miccai import ZeroOneT12DDataset\n",
    "from src.core.models.bayesian_atlas_2dmiccai import VariationalMetamorphicAtlas2dExecuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS :\n",
    "HOME_PATH = '/network/lustre/dtlake01/aramis/users/paul.vernhet'\n",
    "NIFTI_PATH = os.path.join(HOME_PATH, 'Data/MICCAI_dataset/2_datasets/2_t1ce_normalized')\n",
    "BRATS_TENSORS_PATH = os.path.join(HOME_PATH, 'Data/MICCAI_dataset/3_tensors3d/2_t1ce_normalized/0_reduction')\n",
    "\n",
    "EXPERIMENTS_DIR = os.path.join(HOME_PATH, 'Results/MICCAI/2dBraTs/2D_rdm_slice2_normalization_1_reduction/VAE_2020-02-28-09-31-48')\n",
    "ckpt_file = os.path.join(EXPERIMENTS_DIR, 'lightning_logs/version_0/checkpoints/_ckpt_epoch_139.ckpt')\n",
    "metavar_file = os.path.join(EXPERIMENTS_DIR, 'lightning_logs/version_0', 'meta_tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually loading models ( hparams | weights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hparams_from_tags_csv(tags_csv):\n",
    "    from argparse import Namespace\n",
    "    import pandas as pd\n",
    "\n",
    "    tags_df = pd.read_csv(tags_csv)\n",
    "    dic = tags_df.to_dict(orient='records')\n",
    "\n",
    "    ns_dict = {row['key']: convert(row['value']) for row in dic}\n",
    "\n",
    "    ns = Namespace(**ns_dict)\n",
    "    return ns\n",
    "\n",
    "\n",
    "def convert(val):\n",
    "    constructors = [int, float, str]\n",
    "\n",
    "    if type(val) is str:\n",
    "        if val.lower() == 'true':\n",
    "            return True\n",
    "        if val.lower() == 'false':\n",
    "            return False\n",
    "\n",
    "    for c in constructors:\n",
    "        try:\n",
    "            return c(val)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/330 [00:00<00:05, 54.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> hparams loaded\n",
      ">> Creating dataset with 330 files (from 335 available)\n",
      ">> Creating dataset with 16 files (from 125 available)\n",
      ">> Computing online statistics for dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330/330 [00:03<00:00, 92.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Template intensities are torch.Size([1, 160, 192]) = 30720 parameters\n",
      ">> Encoder2d__5_down has 931528 parameters\n",
      ">> DeepDecoder2d__5_up has 933200 parameters\n",
      ">> DeepDecoder2d__4_up has 468320 parameters\n",
      ">> Metamorphic 2D BayesianAtlas has 2363768 parameters\n",
      ">> model_executer loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load hparams\n",
    "hparams = load_hparams_from_tags_csv(metavar_file)\n",
    "print('>> hparams loaded')\n",
    "\n",
    "# craete model, initialize it with hparams | load weights\n",
    "model_executer = VariationalMetamorphicAtlas2dExecuter(hparams)\n",
    "initial_template = model_executer.model.template_intensities.clone()\n",
    "\n",
    "checkpoint = torch.load(ckpt_file, map_location=lambda storage, loc: storage)\n",
    "model_executer.load_state_dict(checkpoint['state_dict'])\n",
    "model = model_executer.model\n",
    "loaded_template = model_executer.model.template_intensities.clone()\n",
    "print('>> model_executer loaded')\n",
    "assert not torch.all(initial_template.eq(loaded_template))\n",
    "\n",
    "# Load state dict \n",
    "#path_to_state_dict = os.path.join(\n",
    "#    path_to_results, \n",
    "#    sorted(fnmatch.filter(os.listdir(path_to_results), 'model__epoch_*.pth'), key=(lambda x: int(x.split('_')[-1][:-4])))[-1])\n",
    "#print('path_to_state_dict = %s' % os.path.basename(path_to_state_dict))\n",
    "#state_dict = torch.load(path_to_state_dict, map_location=lambda storage, loc: storage)\n",
    "\n",
    "# Lead centering parameters\n",
    "#path_to_v_star_average = os.path.join(path_to_results, 'vsa__epoch_%s.npy' % (os.path.basename(path_to_state_dict).split('_')[-1][:-4]))\n",
    "#path_to_n_star_average = os.path.join(path_to_results, 'nsa__epoch_%s.npy' % (os.path.basename(path_to_state_dict).split('_')[-1][:-4]))\n",
    "#print('path_to_v_star_average = %s' % os.path.basename(path_to_v_star_average))\n",
    "#print('path_to_n_star_average = %s' % os.path.basename(path_to_n_star_average))\n",
    "#v_star_average = torch.from_numpy(np.load(path_to_v_star_average))\n",
    "#n_star_average = torch.from_numpy(np.load(path_to_n_star_average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dimension = model.noise_dimension\n",
    "\n",
    "# PRINT TEMPLATE\n",
    "img_01 = 255 * initial_template.squeeze().detach().cpu().numpy()\n",
    "img_02 = 255 * loaded_template.squeeze().detach().cpu().numpy()\n",
    "\n",
    "figsize = 6\n",
    "f, ax = plt.subplots(1, 2, figsize=(2*figsize, figsize))\n",
    "ax[0].imshow(img_01, cmap='gray')\n",
    "ax[1].imshow(img_02, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Learned template')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set CUDA DEVICE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> GPU available.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(hparams.seed)\n",
    "np.random.seed(hparams.seed)\n",
    "\n",
    "if hparams.cuda:\n",
    "    print('>> GPU available.')\n",
    "    DEVICE = torch.device('cuda')\n",
    "    torch.cuda.set_device(hparams.num_gpu)\n",
    "    torch.cuda.manual_seed(hparams.seed)\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print('>> CUDA is not available. Overridding with device = \"cpu\".')\n",
    "    print('>> OMP_NUM_THREADS will be set to ' + str(hparams.num_threads))\n",
    "    os.environ['OMP_NUM_THREADS'] = str(hparams.num_threads)\n",
    "    torch.set_num_threads(hparams.num_threads)\n",
    "    \n",
    "model_executer = model_executer.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check data | reconstruction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [0, 1, 2]\n",
    "data_loader = model_executer.train_dataloader()\n",
    "n = min(5, hparams.nb_train)\n",
    "intensities_to_write = []\n",
    "for batch_idx, intensities in enumerate(data_loader):\n",
    "    if n <= 0:\n",
    "        break\n",
    "    bts = intensities.size(0)\n",
    "    nb_selected = min(bts, n)\n",
    "    intensities_to_write.append(intensities[:nb_selected])\n",
    "    n = n - nb_selected\n",
    "observations = torch.cat(intensities_to_write).to(DEVICE)\n",
    "\n",
    "##############\n",
    "### DEFORM ###\n",
    "##############\n",
    "\n",
    "s, _, a, _ = model.encode(observations)\n",
    "\n",
    "# INIT\n",
    "bts = s.size(0)\n",
    "assert bts == a.size(0)\n",
    "ntp = model.number_of_time_points\n",
    "kws = model.kernel_width__s\n",
    "kwa = model.kernel_width__a\n",
    "dim = model.dimension\n",
    "gs = model.grid_size\n",
    "dgs = model.downsampled_grid_size\n",
    "dsf = model.downsampling_grid\n",
    "\n",
    "v_star = model.decoder__s(s) - model.v_star_average.type(str(s.type()))\n",
    "n_star = model.decoder__a(a) - model.n_star_average.type(str(a.type()))\n",
    "\n",
    "# GAUSSIAN SMOOTHING\n",
    "v = batched_vector_smoothing(v_star, kws, scaled=False)\n",
    "n = batched_scalar_smoothing(n_star, kwa, scaled=False)\n",
    "\n",
    "# NORMALIZE\n",
    "s_norm_squared = torch.sum(s.view(bts, -1) ** 2, dim=1)\n",
    "a_norm_squared = torch.sum(a.view(bts, -1) ** 2, dim=1)\n",
    "v_norm_squared = torch.sum(v * v_star, dim=tuple(range(1, dim + 2)))\n",
    "n_norm_squared = torch.sum(n * n_star, dim=tuple(range(1, dim + 2)))\n",
    "normalizer__s = torch.where(s_norm_squared > 1e-10,\n",
    "                            torch.sqrt(s_norm_squared / v_norm_squared),\n",
    "                            torch.from_numpy(np.array(0.0)).float().type(str(s.type())))\n",
    "normalizer__a = torch.where(a_norm_squared > 1e-10,\n",
    "                            torch.sqrt(a_norm_squared / n_norm_squared),\n",
    "                            torch.from_numpy(np.array(0.0)).float().type(str(a.type())))\n",
    "\n",
    "normalizer__s = normalizer__s.view(*([bts] + (dim + 1) * [1])).expand(v.size())\n",
    "normalizer__a = normalizer__a.view(*([bts] + (dim + 1) * [1])).expand(n.size())\n",
    "v = v * normalizer__s\n",
    "n = n * normalizer__a\n",
    "\n",
    "# FLOW\n",
    "grid = torch.stack(torch.meshgrid([torch.linspace(0.0, elt - 1.0, delt) for elt, delt in zip(gs, dgs)])\n",
    "                   ).type(str(s.type())).view(*([1, dim] + list(dgs))).repeat(*([bts] + (dim + 1) * [1]))\n",
    "\n",
    "x = grid.clone() + v / float(2 ** ntp)\n",
    "for t in range(ntp):\n",
    "    x += batched_vector_interpolation_adaptive(x - grid, x, dsf)\n",
    "\n",
    "# INTERPOLATE\n",
    "intensities = batched_scalar_interpolation_adaptive(model.template_intensities + n, x).float()\n",
    "\n",
    "# WRITE\n",
    "template = model.template_intensities.float().mul(255).cpu()\n",
    "\n",
    "images = []\n",
    "images_ = []\n",
    "sliced_images = []\n",
    "for i in range(bts):\n",
    "    # Get data\n",
    "    appearance = (model.template_intensities + n[i]).float().cpu().mul(255)\n",
    "    shape = batched_scalar_interpolation_adaptive(model.template_intensities.float().cpu(),\n",
    "                                                  x[i].float().unsqueeze(0).detach().cpu())[0].mul(255)\n",
    "    metamorphosis = intensities[i].float().mul(255).cpu()\n",
    "    target = observations[i].float().mul(255).cpu()\n",
    "    \n",
    "    # Get sliced image\n",
    "    images_i = [template.squeeze(1), appearance.squeeze(1), shape.squeeze(1),\n",
    "                metamorphosis.squeeze(1), target.squeeze(1)]\n",
    "    images_ += images_i\n",
    "    images.append(images_i)\n",
    "images_ = torch.cat(images_)\n",
    "vmax = torch.max(images_).detach().numpy()\n",
    "empiric_noise_std = torch.sqrt(torch.sum((intensities - observations) ** 2) / float(intensities.size(0) * noise_dimension)).detach().cpu().numpy()\n",
    "print('empiric_noise_std = %.2E' % empiric_noise_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empiric_noise_std = 4.17E-02\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "### PLOT ###\n",
    "############\n",
    "\n",
    "figsize = 4\n",
    "nrows = len(indexes)\n",
    "ncols = len(images_i)\n",
    "\n",
    "f, axes = plt.subplots(nrows, ncols , figsize=(ncols*figsize, nrows*figsize))\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax = axes.reshape(nrows, ncols)[i, j]\n",
    "        index = indexes[i]\n",
    "\n",
    "        img = images[index][j].detach().cpu().numpy()[0]\n",
    "        if j != 2:\n",
    "            ax.imshow(img, cmap='gray', vmin=0.0, vmax=vmax)\n",
    "\n",
    "        if j == 2:\n",
    "            g = x[index].permute(1, 2, 0).detach().cpu().numpy()\n",
    "            ax.plot([g[:-1, :, 0].ravel(), g[1:, :, 0].ravel()], \n",
    "                    [g[:-1, :, 1].ravel(), g[1:, :, 1].ravel()], 'grey', linewidth=0.5)\n",
    "            ax.plot([g[:, :-1, 0].ravel(), g[:, 1:, 0].ravel()],\n",
    "                    [g[:, :-1, 1].ravel(), g[:, 1:, 1].ravel()], 'grey', linewidth=0.5)\n",
    "        \n",
    "        ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = 5\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "\n",
    "f, axes = plt.subplots(nrows, ncols , figsize=(ncols*figsize, nrows*figsize))\n",
    "\n",
    "# Learned template\n",
    "template = model.template_intensities.detach().cpu().numpy()[0]\n",
    "img = template\n",
    "ax = axes[0, 0]\n",
    "ax.imshow(img, cmap='gray')\n",
    "ax.axis('off')\n",
    "ax.set_title('Learned template')\n",
    "\n",
    "# Average intensity increment\n",
    "n_average = torch.mean(n, dim=0)[0].detach().cpu().numpy()\n",
    "img = n_average\n",
    "ax = axes[0, 1]\n",
    "ax.imshow(img, cmap='gray')\n",
    "ax.axis('off')\n",
    "ax.set_title('Average intensity increment')\n",
    "\n",
    "# Difference\n",
    "img = template + n_average\n",
    "ax = axes[0, 2]\n",
    "ax.imshow(img, cmap='gray')\n",
    "ax.axis('off')\n",
    "ax.set_title('Template + Average increment')\n",
    "\n",
    "# Learned template + increment\n",
    "img = template + n_average\n",
    "ax = axes[1, 0]\n",
    "ax.imshow(img, cmap='gray')\n",
    "ax.axis('off')\n",
    "ax.set_title('Template + Average increment')\n",
    "\n",
    "# Average deformation\n",
    "x_average = torch.mean(x, dim=0)\n",
    "g = x_average.permute(1, 2, 0).detach().cpu().numpy()\n",
    "ax = axes[1, 1]\n",
    "ax.plot([g[:-1, :, 0].ravel(), g[1:, :, 0].ravel()], \n",
    "        [g[:-1, :, 1].ravel(), g[1:, :, 1].ravel()], 'grey', linewidth=0.5)\n",
    "ax.plot([g[:, :-1, 0].ravel(), g[:, 1:, 0].ravel()],\n",
    "        [g[:, :-1, 1].ravel(), g[:, 1:, 1].ravel()], 'grey', linewidth=0.5)\n",
    "ax.axis('off')\n",
    "ax.set_title('Average deformation')\n",
    "\n",
    "# Difference\n",
    "img = batched_scalar_interpolation(model.template_intensities + torch.mean(n, dim=0), \n",
    "                                   x_average.unsqueeze(0))[0].detach().cpu().numpy()[0]\n",
    "ax = axes[1, 2]\n",
    "ax.imshow(img, cmap='gray')\n",
    "ax.axis('off')\n",
    "ax.set_title('Deformed template + Average deformation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "img = n[index, 0].detach().cpu().numpy() - n_average\n",
    "img = img - np.mean(img)\n",
    "\n",
    "figsize = 5\n",
    "f = plt.figure(figsize=(figsize, figsize))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "# plt.title('Learned template')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "thresholds = [0.95, 0.85, 0.75, 0.65, 0.55, 0.54, 0.53, 0.52, 0.51, 0.50]\n",
    "figsize = 4\n",
    "ncols = min(len(thresholds), 5)\n",
    "nrows = len(thresholds) // ncols\n",
    "\n",
    "f, axes = plt.subplots(nrows, ncols , figsize=(ncols*figsize, nrows*figsize))\n",
    "for k, c in enumerate(thresholds):\n",
    "    ax = np.ravel(axes)[k]\n",
    "\n",
    "    mi = np.min(img)\n",
    "    ma = np.max(img)\n",
    "    img_thres = 1.0 * (img > mi + c * (ma - mi)) - 1.0 * (img < ma - c * (ma - mi))\n",
    "\n",
    "    ax.imshow(img_thres, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title('c = %.2f' % c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = s.detach().cpu().numpy()\n",
    "za = a.detach().cpu().numpy()\n",
    "\n",
    "index_a = 0\n",
    "index_b = 2\n",
    "\n",
    "figsize = 4\n",
    "ncols = 4\n",
    "nrows = 1\n",
    "f, axes = plt.subplots(nrows, ncols , figsize=(ncols*figsize, nrows*figsize))\n",
    "\n",
    "### SHAPE \n",
    "pca = PCA(2)\n",
    "zs = pca.fit_transform(zs)\n",
    "\n",
    "ax = axes.ravel()[0]\n",
    "ax.scatter(zs[:, 0], zs[:, 1], s=50, c='tab:blue')\n",
    "ax.scatter(zs[index_a, 0], zs[index_a, 1], s=200, c='tab:red')\n",
    "ax.scatter(zs[index_b, 0], zs[index_b, 1], s=200, c='tab:green')\n",
    "ax.set_title('shape')\n",
    "\n",
    "### APPEARANCE\n",
    "pca = PCA(2)\n",
    "za = pca.fit_transform(za)\n",
    "\n",
    "ax = axes.ravel()[1]\n",
    "ax.scatter(za[:, 0], za[:, 1], s=50, c='tab:blue')\n",
    "ax.scatter(za[index_a, 0], za[index_a, 1], s=200, c='tab:red')\n",
    "ax.scatter(za[index_b, 0], za[index_b, 1], s=200, c='tab:green')\n",
    "ax.set_title('appearance')\n",
    "\n",
    "### Image A\n",
    "\n",
    "ax = axes.ravel()[2]\n",
    "img = images[index_a][3].detach().cpu().numpy()[0]\n",
    "ax.imshow(img, cmap='gray', vmin=0.0, vmax=vmax)\n",
    "ax.set_title('red')\n",
    "\n",
    "### Image B\n",
    "\n",
    "ax = axes.ravel()[3]\n",
    "img = images[index_b][3].detach().cpu().numpy()[0]\n",
    "ax.imshow(img, cmap='gray', vmin=0.0, vmax=vmax)\n",
    "ax.set_title('green')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### \n",
    "### INTERPOLATION\n",
    "###\n",
    "\n",
    "s_start = s[index_a]\n",
    "a_start = a[index_a]\n",
    "s_end = s[index_b]\n",
    "a_end = a[index_b]\n",
    "\n",
    "T = 5\n",
    "dt = 1.0 / float(T-1)\n",
    "\n",
    "imgs = []\n",
    "tol = 1e-10\n",
    "\n",
    "# MIXED INTERPOLATION\n",
    "for t in range(T): \n",
    "    at = (1.0 - t*dt) * a_start + t*dt * a_end\n",
    "    st = (1.0 - t*dt) * s_start + t*dt * s_end\n",
    "    \n",
    "    img = torch.clamp(intensities_mean + intensities_std * model(st.unsqueeze(0), at.unsqueeze(0))[0], tol, 255. - tol)\n",
    "    imgs.append(img)\n",
    "\n",
    "# APPEARANCE INTERPOLATION\n",
    "for t in range(T): \n",
    "    at = (1.0 - t*dt) * a_start + t*dt * a_end\n",
    "    st = s_start\n",
    "    \n",
    "    img = torch.clamp(intensities_mean + intensities_std * model(st.unsqueeze(0), at.unsqueeze(0))[0], tol, 255. - tol)\n",
    "    imgs.append(img)\n",
    "\n",
    "# SHAPE INTERPOLATION\n",
    "for t in range(T): \n",
    "    at = a_start\n",
    "    st = (1.0 - t*dt) * s_start + t*dt * s_end\n",
    "    \n",
    "    img = torch.clamp(intensities_mean + intensities_std * model(st.unsqueeze(0), at.unsqueeze(0))[0], tol, 255. - tol)\n",
    "    imgs.append(img)\n",
    "    \n",
    "imgs = torch.stack(imgs)\n",
    "save_image(imgs, '4_interpolation__start_%d__end_%d.pdf' % (index_a, index_b), \n",
    "           nrow=T, normalize=True, range=(0., float(torch.max(imgs).detach().cpu().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
