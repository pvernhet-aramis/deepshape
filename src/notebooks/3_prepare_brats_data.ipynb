{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandre.bone/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deformetrica\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'itk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4489a52dcc81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# from skimage import exposure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# from skimage.exposure import match_histograms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mitk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m### Visualization ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'itk'"
     ]
    }
   ],
   "source": [
    "### Base ###\n",
    "import os\n",
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import fnmatch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import itertools\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import PIL.Image as pimg\n",
    "import nibabel as nib\n",
    "from multiprocessing import Pool\n",
    "\n",
    "print(os.environ['CONDA_DEFAULT_ENV'])\n",
    "# from skimage import data\n",
    "# from skimage import exposure\n",
    "# from skimage.exposure import match_histograms\n",
    "import itk\n",
    "\n",
    "### Visualization ###\n",
    "#import seaborn as sns\n",
    "#sns.set(color_codes=True)\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "rc('font', **{'family':'serif','serif':['Palatino']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Normalize images with mri_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = []\n",
    "\n",
    "path_to_dataset__in = '/Users/alexandre.bone/Workspace/2020_MICCAI/2_datasets/1_brats_2019'\n",
    "path_to_dataset__out = '/Users/alexandre.bone/Workspace/2020_MICCAI/2_datasets/2_t1_normalized'\n",
    "grades = ['HGG', 'LGG']\n",
    "img_type = 't1'\n",
    "slice_id = 77\n",
    "\n",
    "if not os.path.isdir(path_to_dataset__out): \n",
    "    os.mkdir(path_to_dataset__out)\n",
    "\n",
    "for t in [('1_training', 'train')]: \n",
    "    path_to_t = os.path.join(path_to_dataset__out, t[1])\n",
    "    if not os.path.isdir(path_to_t): \n",
    "        os.mkdir(path_to_t)\n",
    "    for grade in grades: \n",
    "        path_to_subjects = os.path.join(path_to_dataset__in, t[0], grade)\n",
    "        subject_ids = [elt for elt in os.listdir(path_to_subjects) if elt[:5] == 'BraTS']\n",
    "        for subject_id in subject_ids[:1]:\n",
    "            path_to_file__in = os.path.join(path_to_dataset__in, t[0], grade, subject_id, subject_id + '_%s.nii.gz' % img_type)\n",
    "            path_to_file__out = os.path.join(path_to_dataset__out, t[1], grade.lower() + '_' + subject_id[8:] + '_' + img_type)\n",
    "            args.append((path_to_file__in, path_to_file__out + '.nii.gz'))\n",
    "\n",
    "\n",
    "def launch(args):\n",
    "    path_in, path_out = args\n",
    "    cmd = 'mri_normalize %s %s > log' % (path_in, path_out)\n",
    "    print(cmd)\n",
    "    os.system(cmd)\n",
    "\n",
    "# os.system('/applications/FreeSurfer/freesurfer-v6.0.0/SetUpFreeSurfer.sh &> /dev/null')\n",
    "os.system('/Applications/freesurfer/SetUpFreeSurfer.sh &> /dev/null')\n",
    "with Pool(os.cpu_count()) as pool:\n",
    "    pool.map(launch, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract a slice and stock it in png format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = '/Users/alexandre.bone/Workspace/2020_MICCAI/2_datasets/1_brats_2019'\n",
    "t = '1_training'\n",
    "grade = 'HGG'\n",
    "subject_id = 'BraTS19_CBICA_AVF_1'\n",
    "img_type = 't1ce'\n",
    "\n",
    "path_to_file = os.path.join(path_to_dataset, t, grade, subject_id, subject_id + '_%s.nii.gz' % img_type)\n",
    "img = nib.load(path_to_file).get_data()\n",
    "print(img.shape)\n",
    "\n",
    "figsize = 5\n",
    "f = plt.figure(figsize=(figsize, figsize))\n",
    "plt.imshow(np.transpose(img[::-1, ::-1, 77]), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(img.reshape(-1, 1))\n",
    "plt.show()\n",
    "\n",
    "f = plt.figure(figsize=(figsize, figsize))\n",
    "plt.imshow(np.transpose(np.clip(img, 0, 500)[::-1, ::-1, 77]), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(np.clip(img, 0, 500).reshape(-1, 1))\n",
    "plt.show()\n",
    "\n",
    "def sigmoid(x,mi, mx): return mi + (mx-mi)*(lambda t: (1+20**(-t+0.5))**(-1) )( (x-mi)/(mx-mi) )\n",
    "\n",
    "f = plt.figure(figsize=(figsize, figsize))\n",
    "plt.imshow(np.transpose(sigmoid(img, 0, 500)[::-1, ::-1, 77]), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(sigmoid(img, 0, 500).reshape(-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset__in = '/Users/alexandre.bone/Workspace/2020_MICCAI/2_datasets/1_brats_2019'\n",
    "path_to_dataset__out = '/Users/alexandre.bone/Workspace/2020_MICCAI/2_datasets/4_t1ce_slice'\n",
    "grades = ['HGG', 'LGG']\n",
    "img_type = 't1ce'\n",
    "slice_id = 77\n",
    "max_intensity_clip = 500\n",
    "\n",
    "if not os.path.isdir(path_to_dataset__out): \n",
    "    os.mkdir(path_to_dataset__out)\n",
    "\n",
    "# for t in [('1_training', 'train'), ('2_validation', 'test')]: \n",
    "for t in [('1_training', 'train')]: \n",
    "    path_to_t = os.path.join(path_to_dataset__out, t[1])\n",
    "    if not os.path.isdir(path_to_t): \n",
    "        os.mkdir(path_to_t)\n",
    "    for grade in grades: \n",
    "        path_to_subjects = os.path.join(path_to_dataset__in, t[0], grade)\n",
    "        subject_ids = [elt for elt in os.listdir(path_to_subjects) if elt[:5] == 'BraTS']\n",
    "        for subject_id in subject_ids:\n",
    "            path_to_file__in = os.path.join(path_to_dataset__in, t[0], grade, subject_id, subject_id + '_%s.nii.gz' % img_type)\n",
    "            path_to_file__out = os.path.join(path_to_dataset__out, t[1], grade.lower() + '_' + subject_id[8:] + '_' + img_type)\n",
    "            img = nib.load(path_to_file__in).get_data()\n",
    "            img = np.transpose(img[::-1, ::-1, slice_id])\n",
    "# #             max_intensity = max(max_intensity, np.max(img))\n",
    "#             if np.max(img) > threshold: \n",
    "#                 taboo_files.append(os.path.basename(path_to_file__out))\n",
    "            img = np.clip(img, 0, max_intensity_clip)\n",
    "#             maxes.append(np.max(img))\n",
    "#             medians.append(np.median(img[img!=0]))\n",
    "#             mads.append(np.median(np.abs(img[img!=0] - np.median(img[img!=0]))))\n",
    "            tol = 1e-10\n",
    "            img = (np.clip(img.astype('float32') / float(max_intensity_clip), tol, 1.0 - tol) * 255).astype('uint8')\n",
    "            pimg.fromarray(img).save(path_to_file__out + '.png')\n",
    "#             np.save(path_to_file__out, img + '.npy)\n",
    "\n",
    "# print('max_intensity = %d' % max_intensity)\n",
    "plt.hist(np.array(maxes), bins=20)\n",
    "plt.show()\n",
    "print('np.mean(np.array(medians)) = %f' % np.mean(np.array(medians)))\n",
    "print('np.mean(np.array(mads)) = %f' % np.mean(np.array(mads)))\n",
    "print('len(taboo_files) = %d over %d files in total' % \n",
    "      (len(taboo_files), len([elt for elt in os.listdir(path_to_t) if elt[1:3] == 'gg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset__in = '/Users/alexandre.bone/Workspace/2020_MICCAI/2_datasets/1_brats_2019'\n",
    "path_to_dataset__out = '/Users/alexandre.bone/Workspace/2020_MICCAI/2_datasets/2_t1_slice'\n",
    "grades = ['HGG', 'LGG']\n",
    "img_type = 't1'\n",
    "slice_id = 77\n",
    "\n",
    "imgs = []\n",
    "path_to_files_out = []\n",
    "\n",
    "if not os.path.isdir(path_to_dataset__out): \n",
    "    os.mkdir(path_to_dataset__out)\n",
    "\n",
    "# for t in [('1_training', 'train'), ('2_validation', 'test')]: \n",
    "for t in [('1_training', 'train')]: \n",
    "    path_to_t = os.path.join(path_to_dataset__out, t[1])\n",
    "    if not os.path.isdir(path_to_t): \n",
    "        os.mkdir(path_to_t)\n",
    "    for grade in grades: \n",
    "        path_to_subjects = os.path.join(path_to_dataset__in, t[0], grade)\n",
    "        subject_ids = [elt for elt in os.listdir(path_to_subjects) if elt[:5] == 'BraTS']\n",
    "        for subject_id in subject_ids:\n",
    "            path_to_file__in = os.path.join(path_to_dataset__in, t[0], grade, subject_id, subject_id + '_%s.nii.gz' % img_type)\n",
    "            img = nib.load(path_to_file__in).get_data()\n",
    "            img = np.transpose(img[::-1, ::-1, slice_id])\n",
    "            imgs.append(imgs)\n",
    "            path_to_files_out.append(os.path.join(path_to_dataset__out, t[1], grade.lower() + '_' + subject_id[8:] + '_' + img_type))\n",
    "            \n",
    "imgs = np.array(imgs)\n",
    "imgs = (imgs - np.mean(imgs)) / np.std(imgs)\n",
    "\n",
    "for (path, img) in zip(path_to_files_out, imgs): \n",
    "    img = (np.clip(img.astype('float32') / float(normalizer), tol, 1.0 - tol) * 255).astype('uint8')\n",
    "    pimg.fromarray(img).save(path_to_file__out + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
